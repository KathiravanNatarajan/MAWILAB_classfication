{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:51: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\", input_shape=(15, 1), activation=\"relu\")`\n",
      "C:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:52: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 15, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               57472     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 57,986\n",
      "Trainable params: 57,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 383615 samples, validate on 383615 samples\n",
      "Epoch 1/10\n",
      "383615/383615 [==============================] - 48s 126us/step - loss: 0.4567 - acc: 0.7275 - val_loss: 0.4394 - val_acc: 0.7373\n",
      "Epoch 2/10\n",
      "383615/383615 [==============================] - 43s 112us/step - loss: 0.4399 - acc: 0.7358 - val_loss: 0.4282 - val_acc: 0.7359\n",
      "Epoch 3/10\n",
      "383615/383615 [==============================] - 44s 115us/step - loss: 0.4259 - acc: 0.7468 - val_loss: 0.4101 - val_acc: 0.7564\n",
      "Epoch 4/10\n",
      "383615/383615 [==============================] - 47s 123us/step - loss: 0.4181 - acc: 0.7509 - val_loss: 0.4107 - val_acc: 0.7492\n",
      "Epoch 5/10\n",
      "383615/383615 [==============================] - 45s 117us/step - loss: 0.4158 - acc: 0.7519 - val_loss: 0.4044 - val_acc: 0.7570\n",
      "Epoch 6/10\n",
      "383615/383615 [==============================] - 45s 116us/step - loss: 0.4148 - acc: 0.7536 - val_loss: 0.4097 - val_acc: 0.7490\n",
      "Epoch 7/10\n",
      "383615/383615 [==============================] - 50s 130us/step - loss: 0.4141 - acc: 0.7545 - val_loss: 0.4055 - val_acc: 0.7640\n",
      "Epoch 8/10\n",
      "383615/383615 [==============================] - 50s 131us/step - loss: 0.4133 - acc: 0.7564 - val_loss: 0.4024 - val_acc: 0.7580\n",
      "Epoch 9/10\n",
      "383615/383615 [==============================] - 51s 132us/step - loss: 0.4128 - acc: 0.7571 - val_loss: 0.4030 - val_acc: 0.7752\n",
      "Epoch 10/10\n",
      "383615/383615 [==============================] - 51s 132us/step - loss: 0.4126 - acc: 0.7557 - val_loss: 0.4025 - val_acc: 0.7629\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-166d59c7b8ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;31m# cnn.save(\"results/cnn1results/cnn_model.hdf5\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m \u001b[0mcores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "\n",
    "from keras import backend as K\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "\n",
    "X = np.load(\"mawi_features.pkl\")\n",
    "Y = np.load(\"mawi_labels.pkl\")\n",
    "C = np.load(\"mawi_labels.pkl\")\n",
    "T = np.load(\"mawi_features.pkl\")\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lstm_output_size = 128\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(15, 1)))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(2, activation=\"sigmoid\"))\n",
    "print(cnn.summary())\n",
    "# define optimizer and objective, compile cnn\n",
    "\n",
    "\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "# train\n",
    "#checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn1results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "#csv_logger = CSVLogger('results/cnn1results/cnntrainanalysis1.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, epochs=10,validation_data=(X_test, y_test))\n",
    "# cnn.save(\"results/cnn1results/cnn_model.hdf5\")\n",
    "cores = cnn.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
