{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Anaconda\\envs\\GPU\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/gpu:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "\n",
    "from keras import backend as K\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import h5py\n",
    "\n",
    "X = np.load(\"mawi_features.pkl\")\n",
    "Y = np.load(\"mawi_labels.pkl\")\n",
    "C = np.load(\"mawi_labels.pkl\")\n",
    "T = np.load(\"mawi_features.pkl\")\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "# Replicates `model` on 5 GPUs.\n",
    "# This assumes that your machine has 5 available GPUs.\n",
    "cnn = multi_gpu_model(model, gpus=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 15, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               57472     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 57,986\n",
      "Trainable params: 57,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\GPU\\lib\\site-packages\\ipykernel\\__main__.py:2: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(15, 1), padding=\"same\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Anaconda\\envs\\GPU\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(15, 1)))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(2, activation=\"sigmoid\"))\n",
    "print(cnn.summary())\n",
    "# define optimizer and objective, compile cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 383615 samples, validate on 383615 samples\n",
      "Epoch 1/500\n",
      "383615/383615 [==============================] - 97s 253us/step - loss: 0.4575 - acc: 0.7265 - val_loss: 0.4378 - val_acc: 0.7399\n",
      "Epoch 2/500\n",
      "383615/383615 [==============================] - 96s 251us/step - loss: 0.4358 - acc: 0.7451 - val_loss: 0.4190 - val_acc: 0.7489\n",
      "Epoch 3/500\n",
      "383615/383615 [==============================] - 90s 234us/step - loss: 0.4225 - acc: 0.7526 - val_loss: 0.4107 - val_acc: 0.7578\n",
      "Epoch 4/500\n",
      "383615/383615 [==============================] - 84s 218us/step - loss: 0.4184 - acc: 0.7524 - val_loss: 0.4082 - val_acc: 0.7572\n",
      "Epoch 5/500\n",
      "383615/383615 [==============================] - 84s 219us/step - loss: 0.4163 - acc: 0.7520 - val_loss: 0.4065 - val_acc: 0.7488\n",
      "Epoch 6/500\n",
      "383615/383615 [==============================] - 85s 221us/step - loss: 0.4150 - acc: 0.7530 - val_loss: 0.4068 - val_acc: 0.7578\n",
      "Epoch 7/500\n",
      "383615/383615 [==============================] - 84s 219us/step - loss: 0.4135 - acc: 0.7558 - val_loss: 0.4049 - val_acc: 0.7567\n",
      "Epoch 8/500\n",
      "383615/383615 [==============================] - 86s 223us/step - loss: 0.4120 - acc: 0.7582 - val_loss: 0.4024 - val_acc: 0.7695\n",
      "Epoch 9/500\n",
      "383615/383615 [==============================] - 92s 240us/step - loss: 0.4117 - acc: 0.7588 - val_loss: 0.4031 - val_acc: 0.7578\n",
      "Epoch 10/500\n",
      "383615/383615 [==============================] - 101s 264us/step - loss: 0.4111 - acc: 0.7597 - val_loss: 0.4035 - val_acc: 0.7637\n",
      "Epoch 11/500\n",
      "383615/383615 [==============================] - 99s 258us/step - loss: 0.4095 - acc: 0.7621 - val_loss: 0.4010 - val_acc: 0.7630\n",
      "Epoch 12/500\n",
      "383615/383615 [==============================] - 95s 248us/step - loss: 0.4084 - acc: 0.7622 - val_loss: 0.3976 - val_acc: 0.7713\n",
      "Epoch 13/500\n",
      "383615/383615 [==============================] - 95s 247us/step - loss: 0.4088 - acc: 0.7632 - val_loss: 0.3999 - val_acc: 0.7765\n",
      "Epoch 14/500\n",
      "383615/383615 [==============================] - 96s 250us/step - loss: 0.4076 - acc: 0.7637 - val_loss: 0.3969 - val_acc: 0.7759\n",
      "Epoch 15/500\n",
      "383615/383615 [==============================] - 100s 260us/step - loss: 0.4068 - acc: 0.7654 - val_loss: 0.3948 - val_acc: 0.7756\n",
      "Epoch 16/500\n",
      "383615/383615 [==============================] - 98s 257us/step - loss: 0.4058 - acc: 0.7669 - val_loss: 0.3946 - val_acc: 0.7772\n",
      "Epoch 17/500\n",
      "383615/383615 [==============================] - 95s 248us/step - loss: 0.4055 - acc: 0.7672 - val_loss: 0.3960 - val_acc: 0.7768\n",
      "Epoch 18/500\n",
      "383615/383615 [==============================] - 95s 247us/step - loss: 0.4051 - acc: 0.7679 - val_loss: 0.3936 - val_acc: 0.7750\n",
      "Epoch 19/500\n",
      "383615/383615 [==============================] - 95s 248us/step - loss: 0.4045 - acc: 0.7679 - val_loss: 0.3921 - val_acc: 0.7937\n",
      "Epoch 20/500\n",
      "383615/383615 [==============================] - 103s 268us/step - loss: 0.4045 - acc: 0.7674 - val_loss: 0.3953 - val_acc: 0.7637\n",
      "Epoch 21/500\n",
      "383615/383615 [==============================] - 100s 259us/step - loss: 0.4041 - acc: 0.7672 - val_loss: 0.3923 - val_acc: 0.7801\n",
      "Epoch 22/500\n",
      "383615/383615 [==============================] - 93s 242us/step - loss: 0.4025 - acc: 0.7686 - val_loss: 0.3921 - val_acc: 0.7761\n",
      "Epoch 23/500\n",
      "383615/383615 [==============================] - 92s 241us/step - loss: 0.4019 - acc: 0.7683 - val_loss: 0.3883 - val_acc: 0.7769\n",
      "Epoch 24/500\n",
      "383615/383615 [==============================] - 97s 252us/step - loss: 0.4029 - acc: 0.7653 - val_loss: 0.3921 - val_acc: 0.7782\n",
      "Epoch 25/500\n",
      "383615/383615 [==============================] - 98s 256us/step - loss: 0.4017 - acc: 0.7666 - val_loss: 0.3922 - val_acc: 0.7760\n",
      "Epoch 26/500\n",
      "383615/383615 [==============================] - 96s 251us/step - loss: 0.4021 - acc: 0.7661 - val_loss: 0.3892 - val_acc: 0.7712\n",
      "Epoch 27/500\n",
      "383615/383615 [==============================] - 96s 251us/step - loss: 0.4015 - acc: 0.7667 - val_loss: 0.3911 - val_acc: 0.7765\n",
      "Epoch 28/500\n",
      "383615/383615 [==============================] - 98s 256us/step - loss: 0.4013 - acc: 0.7667 - val_loss: 0.3884 - val_acc: 0.7765\n",
      "Epoch 29/500\n",
      "383615/383615 [==============================] - 97s 253us/step - loss: 0.4018 - acc: 0.7662 - val_loss: 0.3895 - val_acc: 0.7765\n",
      "Epoch 30/500\n",
      "383615/383615 [==============================] - 98s 256us/step - loss: 0.4008 - acc: 0.7663 - val_loss: 0.3874 - val_acc: 0.7775\n",
      "Epoch 31/500\n",
      "383615/383615 [==============================] - 95s 248us/step - loss: 0.4020 - acc: 0.7632 - val_loss: 0.3904 - val_acc: 0.7770\n",
      "Epoch 32/500\n",
      "383615/383615 [==============================] - 97s 252us/step - loss: 0.4010 - acc: 0.7655 - val_loss: 0.3895 - val_acc: 0.7758\n",
      "Epoch 33/500\n",
      "383615/383615 [==============================] - 100s 260us/step - loss: 0.4012 - acc: 0.7648 - val_loss: 0.3896 - val_acc: 0.7710\n",
      "Epoch 34/500\n",
      "383615/383615 [==============================] - 100s 260us/step - loss: 0.4011 - acc: 0.7650 - val_loss: 0.3913 - val_acc: 0.7771\n",
      "Epoch 35/500\n",
      "383615/383615 [==============================] - 98s 255us/step - loss: 0.4015 - acc: 0.7625 - val_loss: 0.3900 - val_acc: 0.7756\n",
      "Epoch 36/500\n",
      "383615/383615 [==============================] - 104s 270us/step - loss: 0.4007 - acc: 0.7647 - val_loss: 0.3901 - val_acc: 0.7771\n",
      "Epoch 37/500\n",
      "383615/383615 [==============================] - 104s 272us/step - loss: 0.4007 - acc: 0.7645 - val_loss: 0.3912 - val_acc: 0.7771\n",
      "Epoch 38/500\n",
      "383615/383615 [==============================] - 89s 233us/step - loss: 0.4009 - acc: 0.7646 - val_loss: 0.3900 - val_acc: 0.7764\n",
      "Epoch 39/500\n",
      "383615/383615 [==============================] - 84s 218us/step - loss: 0.4016 - acc: 0.7627 - val_loss: 0.3928 - val_acc: 0.7768\n",
      "Epoch 40/500\n",
      "383615/383615 [==============================] - 84s 219us/step - loss: 0.4012 - acc: 0.7629 - val_loss: 0.3931 - val_acc: 0.7783\n",
      "Epoch 41/500\n",
      "383615/383615 [==============================] - 96s 251us/step - loss: 0.4009 - acc: 0.7634 - val_loss: 0.3932 - val_acc: 0.7709\n",
      "Epoch 42/500\n",
      "383615/383615 [==============================] - 95s 247us/step - loss: 0.4011 - acc: 0.7635 - val_loss: 0.3890 - val_acc: 0.7769\n",
      "Epoch 43/500\n",
      "383615/383615 [==============================] - 100s 261us/step - loss: 0.4006 - acc: 0.7638 - val_loss: 0.3898 - val_acc: 0.7712\n",
      "Epoch 44/500\n",
      "383615/383615 [==============================] - 101s 263us/step - loss: 0.4008 - acc: 0.7634 - val_loss: 0.3885 - val_acc: 0.7763\n",
      "Epoch 45/500\n",
      "383615/383615 [==============================] - 103s 268us/step - loss: 0.4007 - acc: 0.7632 - val_loss: 0.3882 - val_acc: 0.7762\n",
      "Epoch 46/500\n",
      "383615/383615 [==============================] - 101s 264us/step - loss: 0.4009 - acc: 0.7637 - val_loss: 0.3973 - val_acc: 0.7694\n",
      "Epoch 47/500\n",
      "383615/383615 [==============================] - 101s 264us/step - loss: 0.4009 - acc: 0.7641 - val_loss: 0.3902 - val_acc: 0.7780\n",
      "Epoch 48/500\n",
      "383615/383615 [==============================] - 101s 264us/step - loss: 0.4001 - acc: 0.7636 - val_loss: 0.3919 - val_acc: 0.7751\n",
      "Epoch 49/500\n",
      "383615/383615 [==============================] - 101s 262us/step - loss: 0.4007 - acc: 0.7641 - val_loss: 0.3903 - val_acc: 0.7776\n",
      "Epoch 50/500\n",
      "383615/383615 [==============================] - 100s 260us/step - loss: 0.4000 - acc: 0.7629 - val_loss: 0.3882 - val_acc: 0.7769\n",
      "Epoch 51/500\n",
      "383615/383615 [==============================] - 101s 263us/step - loss: 0.4008 - acc: 0.7635 - val_loss: 0.3900 - val_acc: 0.7628\n",
      "Epoch 52/500\n",
      "383615/383615 [==============================] - 100s 261us/step - loss: 0.4002 - acc: 0.7636 - val_loss: 0.3944 - val_acc: 0.7766\n",
      "Epoch 53/500\n",
      "383615/383615 [==============================] - 100s 261us/step - loss: 0.4002 - acc: 0.7637 - val_loss: 0.3907 - val_acc: 0.7767\n",
      "Epoch 54/500\n",
      "383615/383615 [==============================] - 100s 260us/step - loss: 0.4004 - acc: 0.7637 - val_loss: 0.3944 - val_acc: 0.7751\n",
      "Epoch 55/500\n",
      "383615/383615 [==============================] - 100s 261us/step - loss: 0.4003 - acc: 0.7634 - val_loss: 0.3904 - val_acc: 0.7764\n",
      "Epoch 56/500\n",
      "383615/383615 [==============================] - 102s 265us/step - loss: 0.4001 - acc: 0.7632 - val_loss: 0.3894 - val_acc: 0.7771\n",
      "Epoch 57/500\n",
      "383615/383615 [==============================] - 101s 263us/step - loss: 0.4000 - acc: 0.7633 - val_loss: 0.3901 - val_acc: 0.7767\n",
      "Epoch 58/500\n",
      "383615/383615 [==============================] - 101s 263us/step - loss: 0.4002 - acc: 0.7636 - val_loss: 0.3901 - val_acc: 0.7766\n",
      "Epoch 59/500\n",
      "383615/383615 [==============================] - 100s 261us/step - loss: 0.4003 - acc: 0.7635 - val_loss: 0.3880 - val_acc: 0.7778\n",
      "Epoch 60/500\n",
      "383615/383615 [==============================] - 101s 262us/step - loss: 0.4004 - acc: 0.7631 - val_loss: 0.3901 - val_acc: 0.7706\n",
      "Epoch 61/500\n",
      "383615/383615 [==============================] - 101s 264us/step - loss: 0.4001 - acc: 0.7635 - val_loss: 0.3884 - val_acc: 0.7765\n",
      "Epoch 62/500\n",
      "383615/383615 [==============================] - 100s 261us/step - loss: 0.4005 - acc: 0.7637 - val_loss: 0.3879 - val_acc: 0.7764\n",
      "Epoch 63/500\n",
      "383615/383615 [==============================] - 101s 262us/step - loss: 0.4004 - acc: 0.7636 - val_loss: 0.3901 - val_acc: 0.7762\n",
      "Epoch 64/500\n",
      "383615/383615 [==============================] - 99s 258us/step - loss: 0.4001 - acc: 0.7631 - val_loss: 0.3886 - val_acc: 0.7770\n",
      "Epoch 65/500\n",
      "383615/383615 [==============================] - 6776s 18ms/step - loss: 0.3997 - acc: 0.7639 - val_loss: 0.3899 - val_acc: 0.7753\n",
      "Epoch 66/500\n",
      "383615/383615 [==============================] - 148s 385us/step - loss: 0.3996 - acc: 0.7641 - val_loss: 0.3879 - val_acc: 0.7757\n",
      "Epoch 67/500\n",
      "383615/383615 [==============================] - 144s 375us/step - loss: 0.4002 - acc: 0.7635 - val_loss: 0.3906 - val_acc: 0.7751\n",
      "Epoch 68/500\n",
      "383615/383615 [==============================] - 149s 389us/step - loss: 0.4003 - acc: 0.7631 - val_loss: 0.3885 - val_acc: 0.7768\n",
      "Epoch 69/500\n",
      "383615/383615 [==============================] - 14940s 39ms/step - loss: 0.3996 - acc: 0.7639 - val_loss: 0.3892 - val_acc: 0.7744\n",
      "Epoch 70/500\n",
      "383615/383615 [==============================] - 155s 405us/step - loss: 0.3999 - acc: 0.7636 - val_loss: 0.3882 - val_acc: 0.7767\n",
      "Epoch 71/500\n",
      "383615/383615 [==============================] - 147s 384us/step - loss: 0.4000 - acc: 0.7632 - val_loss: 0.3896 - val_acc: 0.7701\n",
      "Epoch 72/500\n",
      "383615/383615 [==============================] - 152s 395us/step - loss: 0.4002 - acc: 0.7633 - val_loss: 0.3905 - val_acc: 0.7885\n",
      "Epoch 73/500\n",
      "383615/383615 [==============================] - 163s 425us/step - loss: 0.3998 - acc: 0.7629 - val_loss: 0.3890 - val_acc: 0.7751\n",
      "Epoch 74/500\n",
      "383615/383615 [==============================] - 139s 363us/step - loss: 0.3998 - acc: 0.7637 - val_loss: 0.3886 - val_acc: 0.7756\n",
      "Epoch 75/500\n",
      "383615/383615 [==============================] - 140s 364us/step - loss: 0.3999 - acc: 0.7636 - val_loss: 0.3908 - val_acc: 0.7876\n",
      "Epoch 76/500\n",
      "383615/383615 [==============================] - 147s 383us/step - loss: 0.3998 - acc: 0.7630 - val_loss: 0.3882 - val_acc: 0.7760\n",
      "Epoch 77/500\n",
      "383615/383615 [==============================] - 155s 405us/step - loss: 0.3996 - acc: 0.7622 - val_loss: 0.3903 - val_acc: 0.7784\n",
      "Epoch 78/500\n",
      "383615/383615 [==============================] - 146s 381us/step - loss: 0.3998 - acc: 0.7631 - val_loss: 0.3873 - val_acc: 0.7776\n",
      "Epoch 79/500\n",
      "383615/383615 [==============================] - 233s 607us/step - loss: 0.3994 - acc: 0.7644 - val_loss: 0.3882 - val_acc: 0.7744\n",
      "Epoch 80/500\n",
      "383615/383615 [==============================] - 291s 760us/step - loss: 0.3995 - acc: 0.7629 - val_loss: 0.3898 - val_acc: 0.7642\n",
      "Epoch 81/500\n",
      "383615/383615 [==============================] - 209s 545us/step - loss: 0.3991 - acc: 0.7651 - val_loss: 0.3910 - val_acc: 0.7707\n",
      "Epoch 82/500\n",
      "383615/383615 [==============================] - 95s 249us/step - loss: 0.3994 - acc: 0.7630 - val_loss: 0.3868 - val_acc: 0.7754\n",
      "Epoch 83/500\n",
      "383615/383615 [==============================] - 98s 255us/step - loss: 0.3993 - acc: 0.7640 - val_loss: 0.3886 - val_acc: 0.7770\n",
      "Epoch 84/500\n",
      "383615/383615 [==============================] - 95s 249us/step - loss: 0.3990 - acc: 0.7635 - val_loss: 0.3879 - val_acc: 0.7764\n",
      "Epoch 85/500\n",
      "383615/383615 [==============================] - 104s 271us/step - loss: 0.3994 - acc: 0.7637 - val_loss: 0.3873 - val_acc: 0.7776\n",
      "Epoch 86/500\n",
      "383615/383615 [==============================] - 102s 267us/step - loss: 0.3992 - acc: 0.7637 - val_loss: 0.3882 - val_acc: 0.7788\n",
      "Epoch 87/500\n",
      "383615/383615 [==============================] - 99s 258us/step - loss: 0.3994 - acc: 0.7633 - val_loss: 0.3916 - val_acc: 0.7753\n",
      "Epoch 88/500\n",
      "383615/383615 [==============================] - 1787s 5ms/step - loss: 0.3991 - acc: 0.7624 - val_loss: 0.3865 - val_acc: 0.7770\n",
      "Epoch 89/500\n",
      "383615/383615 [==============================] - 90s 235us/step - loss: 0.3989 - acc: 0.7638 - val_loss: 0.3901 - val_acc: 0.7774\n",
      "Epoch 90/500\n",
      "383615/383615 [==============================] - 103s 270us/step - loss: 0.3981 - acc: 0.7642 - val_loss: 0.3871 - val_acc: 0.7746\n",
      "Epoch 91/500\n",
      "383615/383615 [==============================] - 93s 244us/step - loss: 0.3988 - acc: 0.7644 - val_loss: 0.3870 - val_acc: 0.7860\n",
      "Epoch 92/500\n",
      "383615/383615 [==============================] - 101s 264us/step - loss: 0.3987 - acc: 0.7644 - val_loss: 0.3893 - val_acc: 0.7762\n",
      "Epoch 93/500\n",
      "383615/383615 [==============================] - 101s 264us/step - loss: 0.3982 - acc: 0.7634 - val_loss: 0.3859 - val_acc: 0.7769\n",
      "Epoch 94/500\n",
      "383615/383615 [==============================] - 101s 264us/step - loss: 0.3986 - acc: 0.7637 - val_loss: 0.3872 - val_acc: 0.7782\n",
      "Epoch 95/500\n",
      "383615/383615 [==============================] - 100s 260us/step - loss: 0.3984 - acc: 0.7640 - val_loss: 0.3913 - val_acc: 0.7753\n",
      "Epoch 96/500\n",
      "383615/383615 [==============================] - 100s 262us/step - loss: 0.3982 - acc: 0.7632 - val_loss: 0.3872 - val_acc: 0.7724\n",
      "Epoch 97/500\n",
      "383615/383615 [==============================] - 102s 267us/step - loss: 0.3979 - acc: 0.7649 - val_loss: 0.3872 - val_acc: 0.7770\n",
      "Epoch 98/500\n",
      "383615/383615 [==============================] - 101s 264us/step - loss: 0.3989 - acc: 0.7627 - val_loss: 0.3898 - val_acc: 0.7760\n",
      "Epoch 99/500\n",
      "383615/383615 [==============================] - 101s 263us/step - loss: 0.3977 - acc: 0.7643 - val_loss: 0.3856 - val_acc: 0.7767\n",
      "Epoch 100/500\n",
      "383615/383615 [==============================] - 100s 262us/step - loss: 0.3986 - acc: 0.7629 - val_loss: 0.3876 - val_acc: 0.7761\n",
      "Epoch 101/500\n",
      "383615/383615 [==============================] - 142s 371us/step - loss: 0.3978 - acc: 0.7643 - val_loss: 0.3911 - val_acc: 0.7743\n",
      "Epoch 102/500\n",
      "383615/383615 [==============================] - 150s 392us/step - loss: 0.3976 - acc: 0.7641 - val_loss: 0.3855 - val_acc: 0.7841\n",
      "Epoch 103/500\n",
      "383615/383615 [==============================] - 152s 397us/step - loss: 0.3981 - acc: 0.7636 - val_loss: 0.3868 - val_acc: 0.7751\n",
      "Epoch 104/500\n",
      "383615/383615 [==============================] - 158s 412us/step - loss: 0.3976 - acc: 0.7642 - val_loss: 0.3840 - val_acc: 0.7762\n",
      "Epoch 105/500\n",
      "383615/383615 [==============================] - 217s 565us/step - loss: 0.3989 - acc: 0.7626 - val_loss: 0.3885 - val_acc: 0.7720\n",
      "Epoch 106/500\n",
      "383615/383615 [==============================] - 169s 440us/step - loss: 0.3980 - acc: 0.7638 - val_loss: 0.3874 - val_acc: 0.7759\n",
      "Epoch 107/500\n",
      "383615/383615 [==============================] - 102s 266us/step - loss: 0.3971 - acc: 0.7646 - val_loss: 0.3871 - val_acc: 0.7843\n",
      "Epoch 108/500\n",
      "383615/383615 [==============================] - 101s 264us/step - loss: 0.3981 - acc: 0.7637 - val_loss: 0.3889 - val_acc: 0.7836\n",
      "Epoch 109/500\n",
      "383615/383615 [==============================] - 101s 263us/step - loss: 0.3992 - acc: 0.7586 - val_loss: 0.3876 - val_acc: 0.7774\n",
      "Epoch 110/500\n",
      "383615/383615 [==============================] - 102s 265us/step - loss: 0.3992 - acc: 0.7585 - val_loss: 0.3890 - val_acc: 0.7705\n",
      "Epoch 111/500\n",
      "383615/383615 [==============================] - 106s 277us/step - loss: 0.3975 - acc: 0.7642 - val_loss: 0.3902 - val_acc: 0.7948\n",
      "Epoch 112/500\n",
      "383615/383615 [==============================] - 97s 254us/step - loss: 0.3970 - acc: 0.7662 - val_loss: 0.3872 - val_acc: 0.7827\n",
      "Epoch 113/500\n",
      "383615/383615 [==============================] - 99s 258us/step - loss: 0.3971 - acc: 0.7650 - val_loss: 0.3866 - val_acc: 0.7982\n",
      "Epoch 114/500\n",
      "383615/383615 [==============================] - 99s 258us/step - loss: 0.3966 - acc: 0.7661 - val_loss: 0.3884 - val_acc: 0.7842\n",
      "Epoch 115/500\n",
      "383615/383615 [==============================] - 99s 257us/step - loss: 0.3976 - acc: 0.7641 - val_loss: 0.3888 - val_acc: 0.7769\n",
      "Epoch 116/500\n",
      "383615/383615 [==============================] - 100s 260us/step - loss: 0.3980 - acc: 0.7618 - val_loss: 0.3884 - val_acc: 0.7782\n",
      "Epoch 117/500\n",
      "383615/383615 [==============================] - 101s 262us/step - loss: 0.3986 - acc: 0.7599 - val_loss: 0.3838 - val_acc: 0.7901\n",
      "Epoch 118/500\n",
      "383615/383615 [==============================] - 101s 264us/step - loss: 0.3966 - acc: 0.7656 - val_loss: 0.3816 - val_acc: 0.7795\n",
      "Epoch 119/500\n",
      "383615/383615 [==============================] - 100s 262us/step - loss: 0.3965 - acc: 0.7671 - val_loss: 0.3912 - val_acc: 0.7579\n",
      "Epoch 120/500\n",
      "383615/383615 [==============================] - 101s 263us/step - loss: 0.3989 - acc: 0.7577 - val_loss: 0.3919 - val_acc: 0.7984\n",
      "Epoch 121/500\n",
      "383615/383615 [==============================] - 100s 261us/step - loss: 0.3975 - acc: 0.7644 - val_loss: 0.3839 - val_acc: 0.7832\n",
      "Epoch 122/500\n",
      "383615/383615 [==============================] - 99s 257us/step - loss: 0.3975 - acc: 0.7651 - val_loss: 0.3835 - val_acc: 0.7781\n",
      "Epoch 123/500\n",
      "383615/383615 [==============================] - 101s 262us/step - loss: 0.3965 - acc: 0.7668 - val_loss: 0.3817 - val_acc: 0.7851\n",
      "Epoch 124/500\n",
      "383615/383615 [==============================] - 98s 255us/step - loss: 0.3958 - acc: 0.7673 - val_loss: 0.3801 - val_acc: 0.7845\n",
      "Epoch 125/500\n",
      "383615/383615 [==============================] - 90s 235us/step - loss: 0.3975 - acc: 0.7616 - val_loss: 0.3879 - val_acc: 0.7874\n",
      "Epoch 126/500\n",
      "383615/383615 [==============================] - 82s 215us/step - loss: 0.3970 - acc: 0.7641 - val_loss: 0.3832 - val_acc: 0.7825\n",
      "Epoch 127/500\n",
      "383615/383615 [==============================] - 83s 216us/step - loss: 0.3961 - acc: 0.7655 - val_loss: 0.3828 - val_acc: 0.7880\n",
      "Epoch 128/500\n",
      "383615/383615 [==============================] - 84s 219us/step - loss: 0.3968 - acc: 0.7666 - val_loss: 0.3835 - val_acc: 0.7715\n",
      "Epoch 129/500\n",
      "383615/383615 [==============================] - 84s 219us/step - loss: 0.3967 - acc: 0.7662 - val_loss: 0.3905 - val_acc: 0.7536\n",
      "Epoch 130/500\n",
      "383615/383615 [==============================] - 84s 218us/step - loss: 0.3970 - acc: 0.7657 - val_loss: 0.3842 - val_acc: 0.7798\n",
      "Epoch 131/500\n",
      "383615/383615 [==============================] - 83s 217us/step - loss: 0.3970 - acc: 0.7654 - val_loss: 0.3848 - val_acc: 0.7993\n",
      "Epoch 132/500\n",
      "383615/383615 [==============================] - 84s 218us/step - loss: 0.3959 - acc: 0.7689 - val_loss: 0.3859 - val_acc: 0.7948\n",
      "Epoch 133/500\n",
      "383615/383615 [==============================] - 85s 222us/step - loss: 0.3973 - acc: 0.7667 - val_loss: 0.3901 - val_acc: 0.7564\n",
      "Epoch 134/500\n",
      "383615/383615 [==============================] - 86s 223us/step - loss: 0.3972 - acc: 0.7666 - val_loss: 0.3849 - val_acc: 0.7805\n",
      "Epoch 135/500\n",
      "383615/383615 [==============================] - 92s 241us/step - loss: 0.3958 - acc: 0.7682 - val_loss: 0.3830 - val_acc: 0.7907\n",
      "Epoch 136/500\n",
      "383615/383615 [==============================] - 83s 217us/step - loss: 0.3965 - acc: 0.7676 - val_loss: 0.3829 - val_acc: 0.7796\n",
      "Epoch 137/500\n",
      "383615/383615 [==============================] - 87s 227us/step - loss: 0.3959 - acc: 0.7691 - val_loss: 0.3854 - val_acc: 0.7811\n",
      "Epoch 138/500\n",
      "383615/383615 [==============================] - 90s 234us/step - loss: 0.3966 - acc: 0.7662 - val_loss: 0.3844 - val_acc: 0.7808\n",
      "Epoch 139/500\n",
      "383615/383615 [==============================] - 115s 298us/step - loss: 0.3971 - acc: 0.7634 - val_loss: 0.3867 - val_acc: 0.7872\n",
      "Epoch 140/500\n",
      "383615/383615 [==============================] - 146s 380us/step - loss: 0.3961 - acc: 0.7664 - val_loss: 0.3839 - val_acc: 0.7797\n",
      "Epoch 141/500\n",
      "383615/383615 [==============================] - 143s 374us/step - loss: 0.3961 - acc: 0.7677 - val_loss: 0.3875 - val_acc: 0.7975\n",
      "Epoch 142/500\n",
      "383615/383615 [==============================] - 141s 366us/step - loss: 0.3961 - acc: 0.7663 - val_loss: 0.3810 - val_acc: 0.7848\n",
      "Epoch 143/500\n",
      "383615/383615 [==============================] - 154s 400us/step - loss: 0.3966 - acc: 0.7650 - val_loss: 0.3807 - val_acc: 0.7841\n",
      "Epoch 144/500\n",
      "383615/383615 [==============================] - 144s 374us/step - loss: 0.3960 - acc: 0.7676 - val_loss: 0.3892 - val_acc: 0.7603\n",
      "Epoch 145/500\n",
      "383615/383615 [==============================] - 125s 327us/step - loss: 0.3977 - acc: 0.7617 - val_loss: 0.3826 - val_acc: 0.7787\n",
      "Epoch 146/500\n",
      "383615/383615 [==============================] - 107s 280us/step - loss: 0.3957 - acc: 0.7681 - val_loss: 0.3829 - val_acc: 0.7954\n",
      "Epoch 147/500\n",
      "383615/383615 [==============================] - 128s 334us/step - loss: 0.3950 - acc: 0.7709 - val_loss: 0.3903 - val_acc: 0.7558\n",
      "Epoch 148/500\n",
      "383615/383615 [==============================] - 154s 402us/step - loss: 0.3946 - acc: 0.7703 - val_loss: 0.3797 - val_acc: 0.7890\n",
      "Epoch 149/500\n",
      "383615/383615 [==============================] - 159s 414us/step - loss: 0.3953 - acc: 0.7702 - val_loss: 0.3886 - val_acc: 0.7600\n",
      "Epoch 150/500\n",
      "383615/383615 [==============================] - 156s 406us/step - loss: 0.3943 - acc: 0.7706 - val_loss: 0.3862 - val_acc: 0.7802\n",
      "Epoch 151/500\n",
      "383615/383615 [==============================] - 108s 281us/step - loss: 0.3952 - acc: 0.7690 - val_loss: 0.3787 - val_acc: 0.7854\n",
      "Epoch 152/500\n",
      "383615/383615 [==============================] - 100s 260us/step - loss: 0.3952 - acc: 0.7689 - val_loss: 0.3897 - val_acc: 0.7596\n",
      "Epoch 153/500\n",
      "383615/383615 [==============================] - 100s 262us/step - loss: 0.3950 - acc: 0.7677 - val_loss: 0.3843 - val_acc: 0.7869\n",
      "Epoch 154/500\n",
      "383615/383615 [==============================] - 100s 260us/step - loss: 0.3943 - acc: 0.7703 - val_loss: 0.3831 - val_acc: 0.7846\n",
      "Epoch 155/500\n",
      "383615/383615 [==============================] - 100s 260us/step - loss: 0.3967 - acc: 0.7636 - val_loss: 0.3805 - val_acc: 0.7845\n",
      "Epoch 156/500\n",
      "383615/383615 [==============================] - 95s 249us/step - loss: 0.3950 - acc: 0.7685 - val_loss: 0.3851 - val_acc: 0.7889\n",
      "Epoch 157/500\n",
      "383615/383615 [==============================] - 96s 250us/step - loss: 0.3933 - acc: 0.7731 - val_loss: 0.3826 - val_acc: 0.7893\n",
      "Epoch 158/500\n",
      "383615/383615 [==============================] - 92s 241us/step - loss: 0.3943 - acc: 0.7700 - val_loss: 0.3807 - val_acc: 0.7894\n",
      "Epoch 159/500\n",
      "383615/383615 [==============================] - 95s 249us/step - loss: 0.3948 - acc: 0.7694 - val_loss: 0.3822 - val_acc: 0.7839\n",
      "Epoch 160/500\n",
      "383615/383615 [==============================] - 93s 241us/step - loss: 0.3944 - acc: 0.7691 - val_loss: 0.3825 - val_acc: 0.7887\n",
      "Epoch 161/500\n",
      "383615/383615 [==============================] - 83s 216us/step - loss: 0.3942 - acc: 0.7720 - val_loss: 0.3795 - val_acc: 0.7853\n",
      "Epoch 162/500\n",
      "383615/383615 [==============================] - 102s 266us/step - loss: 0.3946 - acc: 0.7696 - val_loss: 0.3815 - val_acc: 0.7893\n",
      "Epoch 163/500\n",
      "383615/383615 [==============================] - 99s 257us/step - loss: 0.3953 - acc: 0.7660 - val_loss: 0.3841 - val_acc: 0.7989\n",
      "Epoch 164/500\n",
      "383615/383615 [==============================] - 98s 256us/step - loss: 0.3939 - acc: 0.7716 - val_loss: 0.3910 - val_acc: 0.7902\n",
      "Epoch 165/500\n",
      "383615/383615 [==============================] - 100s 261us/step - loss: 0.3943 - acc: 0.7682 - val_loss: 0.3838 - val_acc: 0.8035\n",
      "Epoch 166/500\n",
      "383615/383615 [==============================] - 99s 259us/step - loss: 0.3944 - acc: 0.7679 - val_loss: 0.3860 - val_acc: 0.8120\n",
      "Epoch 167/500\n",
      "383615/383615 [==============================] - 100s 262us/step - loss: 0.3935 - acc: 0.7719 - val_loss: 0.3779 - val_acc: 0.7795\n",
      "Epoch 168/500\n",
      "383615/383615 [==============================] - 106s 275us/step - loss: 0.3941 - acc: 0.7700 - val_loss: 0.3798 - val_acc: 0.7840\n",
      "Epoch 169/500\n",
      "383615/383615 [==============================] - 110s 286us/step - loss: 0.3937 - acc: 0.7698 - val_loss: 0.3796 - val_acc: 0.7873\n",
      "Epoch 170/500\n",
      "383615/383615 [==============================] - 99s 258us/step - loss: 0.3941 - acc: 0.7696 - val_loss: 0.3812 - val_acc: 0.7937\n",
      "Epoch 171/500\n",
      "383615/383615 [==============================] - 102s 265us/step - loss: 0.3933 - acc: 0.7721 - val_loss: 0.3798 - val_acc: 0.7997\n",
      "Epoch 172/500\n",
      "383615/383615 [==============================] - 102s 265us/step - loss: 0.3938 - acc: 0.7699 - val_loss: 0.3783 - val_acc: 0.7989\n",
      "Epoch 173/500\n",
      "383615/383615 [==============================] - 102s 265us/step - loss: 0.3930 - acc: 0.7726 - val_loss: 0.3779 - val_acc: 0.7949\n",
      "Epoch 174/500\n",
      "383615/383615 [==============================] - 100s 260us/step - loss: 0.3942 - acc: 0.7691 - val_loss: 0.3842 - val_acc: 0.8024\n",
      "Epoch 175/500\n",
      "383615/383615 [==============================] - 105s 273us/step - loss: 0.3932 - acc: 0.7713 - val_loss: 0.3816 - val_acc: 0.7876\n",
      "Epoch 176/500\n",
      "383615/383615 [==============================] - 102s 265us/step - loss: 0.3937 - acc: 0.7702 - val_loss: 0.3767 - val_acc: 0.7884\n",
      "Epoch 177/500\n",
      "383615/383615 [==============================] - 96s 250us/step - loss: 0.3947 - acc: 0.7677 - val_loss: 0.3846 - val_acc: 0.7993\n",
      "Epoch 178/500\n",
      "383615/383615 [==============================] - 98s 256us/step - loss: 0.3934 - acc: 0.7716 - val_loss: 0.3847 - val_acc: 0.8005\n",
      "Epoch 179/500\n",
      "383615/383615 [==============================] - 88s 230us/step - loss: 0.3943 - acc: 0.7690 - val_loss: 0.3811 - val_acc: 0.7837\n",
      "Epoch 180/500\n",
      "383615/383615 [==============================] - 91s 237us/step - loss: 0.3938 - acc: 0.7682 - val_loss: 0.3782 - val_acc: 0.7912\n",
      "Epoch 181/500\n",
      "383615/383615 [==============================] - 100s 260us/step - loss: 0.3942 - acc: 0.7676 - val_loss: 0.3875 - val_acc: 0.7597\n",
      "Epoch 182/500\n",
      "383615/383615 [==============================] - 99s 257us/step - loss: 0.3945 - acc: 0.7679 - val_loss: 0.3785 - val_acc: 0.7858\n",
      "Epoch 183/500\n",
      "383615/383615 [==============================] - 94s 246us/step - loss: 0.3937 - acc: 0.7698 - val_loss: 0.3808 - val_acc: 0.7810\n",
      "Epoch 184/500\n",
      "383615/383615 [==============================] - 96s 251us/step - loss: 0.3926 - acc: 0.7727 - val_loss: 0.3773 - val_acc: 0.7885\n",
      "Epoch 185/500\n",
      "383615/383615 [==============================] - 96s 249us/step - loss: 0.3928 - acc: 0.7721 - val_loss: 0.3820 - val_acc: 0.7801\n",
      "Epoch 186/500\n",
      "383584/383615 [============================>.] - ETA: 0s - loss: 0.3934 - acc: 0.7706"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-eb538f213b8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"binary_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\envs\\GPU\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\GPU\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\GPU\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1247\u001b[0m                             val_outs = self._test_loop(val_f, val_ins,\n\u001b[0;32m   1248\u001b[0m                                                        \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m                                                        verbose=0)\n\u001b[0m\u001b[0;32m   1250\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                                 \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\GPU\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1424\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1427\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "# train\n",
    "cnn.fit(X_train, y_train, epochs=500,validation_data=(X_test, y_test))\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"cnn1D_MawiLAB.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"cnn1D_MawiLAB.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:GPU]",
   "language": "python",
   "name": "conda-env-GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
