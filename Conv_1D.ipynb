{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "mawi_features = np.load(\"mawi_features.pkl\")\n",
    "mawi_labels = np.load(\"mawi_labels.pkl\") \n",
    "mawi_features = np.reshape(mawi_features, [-1,15,1])\n",
    "\n",
    "def conv1D_Net1(input_1d):\n",
    "    kernel_1d1 = tf.reshape(tf.truncated_normal([64,1,1], dtype=tf.float32), [64,1,1])\n",
    "    conv1d = tf.nn.conv1d(input_1d, kernel_1d1, stride=1, padding='SAME')\n",
    "    pool1 = tf.nn.pool(conv1d, [2], 'MAX', 'SAME', strides = [2])\n",
    "    #pool1 = tf.nn.dropout(pool1, keep_prob)\n",
    "     #Flattenning the output of ConvNets \n",
    "    flat_conv2 = tf.contrib.layers.flatten(pool1)\n",
    "\n",
    "    datasize = flat_conv2.get_shape().as_list()[1]\n",
    "    W_fc1 = tf.Variable(tf.truncated_normal([datasize, 128], stddev=0.02))\n",
    "    b_fc1 = tf.Variable(tf.zeros([128]))\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(flat_conv2,W_fc1)+b_fc1)\n",
    "    h_fc1 = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    # Output layer\n",
    "    y_conv = tf.layers.dense(inputs=h_fc1, units=2)\n",
    "    return y_conv\n",
    "    \n",
    "def batches(batch_size, features, labels):\n",
    "    assert len(features) == len(labels)\n",
    "    out_batches = []\n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batches = [features[start_i:end_i], labels[start_i:end_i]] \n",
    "        out_batches.append(batches)\n",
    "    return out_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   - Training Accuracy: 0.6361612677574158 loss 56.91929626464844\n",
      "Epoch 20  - Training Accuracy: 0.3602518141269684 loss 29.01545524597168\n",
      "Epoch 40  - Training Accuracy: 0.6586108207702637 loss 51.16014099121094\n",
      "Epoch 60  - Training Accuracy: 0.3643861711025238 loss 22.44011878967285\n",
      "Epoch 80  - Training Accuracy: 0.29970672726631165 loss 142.94219970703125\n",
      "Epoch 100 - Training Accuracy: 0.3423197865486145 loss 30.80449104309082\n",
      "Epoch 120 - Training Accuracy: 0.6949493885040283 loss 87.51692199707031\n",
      "Epoch 140 - Training Accuracy: 0.6356972455978394 loss 72.38109588623047\n",
      "Epoch 160 - Training Accuracy: 0.29879698157310486 loss 124.19244384765625\n",
      "Epoch 180 - Training Accuracy: 0.37534767389297485 loss 56.528076171875\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2 \n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, 15, 1])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(dtype=tf.float32, name = \"keep_prob\")\n",
    "\n",
    "# Learning rate \n",
    "learning_rate = 0.5\n",
    "\n",
    "# Output of the model \n",
    "output = conv1D_Net1(features)\n",
    "\n",
    "# Calculating cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = output, labels = labels))\n",
    "# Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(output,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Train or test with this batch size\n",
    "batchSize =  128 \n",
    "epochs = 200\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) \n",
    "    #train_batches = batches(batchSize, mawi_features, mawi_labels)\n",
    "    \n",
    "    for epoch in range(epochs): \n",
    "        #for batch_features, batch_labels in train_batches: \n",
    "        #    train_data = {features: batch_features, labels : batch_labels, keep_prob : 0.7}\n",
    "        training_accuracy = sess.run(accuracy, feed_dict = {features: mawi_features, labels : mawi_labels, keep_prob : 1} )\n",
    "            # Print status for every 10 epochs\n",
    "        cost_val = sess.run(cost, feed_dict = {features: mawi_features, labels : mawi_labels, keep_prob : 1} )\n",
    "        if epoch % 20 == 0:\n",
    "            print('Epoch {:<3} - Training Accuracy: {} loss {}'.format(epoch,training_accuracy, cost_val))\n",
    "\n",
    "    # Save the variables to disk.\n",
    "    save_model_path = './image_classification'\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
