{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongh\\Anaconda3\\envs\\tf\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_first\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import argparse\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization, regularizers\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical\n",
    "K.set_image_dim_ordering('th')\n",
    "print(K.image_data_format())\n",
    "\n",
    "## required for efficient GPU use\n",
    "import tensorflow as tf\n",
    "from keras.backend import tensorflow_backend\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "session = tf.Session(config=config)\n",
    "tensorflow_backend.set_session(session)\n",
    "## required for efficient GPU use\n",
    "\n",
    "import os\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np # linear algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path='./result/cnn_shallow_mawi2.h5'\n",
    "\n",
    "# prepare callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_acc', \n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        verbose=1),\n",
    "    ModelCheckpoint(model_path,\n",
    "        monitor='val_acc', \n",
    "        save_best_only=True, \n",
    "        mode='max',\n",
    "        verbose=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (40780, 4)\n",
      "y_train shape: (40780, 2)\n",
      "x_test shape: (42398, 4)\n",
      "y_test shape: (42398, 2)\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "\n",
    "class dataset:\n",
    "    mawi_train_2labels = pd.read_pickle(\"dataset/preprocessed_mawi_train_2labels(001).pkl\")\n",
    "    mawi_test_2labels = pd.read_pickle(\"dataset/preprocessed_mawi_test_2labels(003).pkl\")\n",
    "    \n",
    "    \n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['status_anomaly','status_normal']\n",
    "    \n",
    "    x_input = dataset.mawi_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.mawi_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.mawi_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.mawi_test_2labels.loc[:,output_columns_2labels]\n",
    "    \n",
    "    ss = pp.StandardScaler()\n",
    "    \n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.fit_transform(x_test_input)\n",
    "    \n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "        \n",
    "    print('x_train shape: {}'.format(x_train.shape))\n",
    "    print('y_train shape: {}'.format(y_train.shape))\n",
    "    print('x_test shape: {}'.format(x_test.shape))\n",
    "    print('y_test shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape after reshape: (40780, 4, 1)\n",
      "test shape after reshape: (42398, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "#reshape data\n",
    "X_train = np.reshape(preprocess.x_train, (preprocess.x_train.shape[0], preprocess.x_train.shape[1], 1))\n",
    "X_test = np.reshape(preprocess.x_test, (preprocess.x_test.shape[0], preprocess.x_test.shape[1], 1))\n",
    "\n",
    "print('train shape after reshape: {}'.format(X_train.shape))\n",
    "print('test shape after reshape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#size of parameters\n",
    "batch_size = 64\n",
    "num_classes = 2\n",
    "epochs = 20\n",
    "filter_size=3\n",
    "#noise = 1\n",
    "droprate=0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dongh\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 4, 64)             256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                12288     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 13,186\n",
      "Trainable params: 12,930\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Start Neural Network\n",
    "model = Sequential()\n",
    "\n",
    "#convolution 1st layer\n",
    "model.add(Conv1D(64, kernel_size=(filter_size), padding=\"same\",\n",
    "                 activation='relu',\n",
    "                 input_shape=(4, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(droprate))\n",
    "model.add(MaxPooling1D(strides=1))\n",
    "\n",
    "#FCN layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(droprate))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40780 samples, validate on 42398 samples\n",
      "Epoch 1/20\n",
      "40780/40780 [==============================] - 3s 79us/step - loss: 0.4328 - acc: 0.8016 - val_loss: 0.5988 - val_acc: 0.6791\n",
      "Epoch 2/20\n",
      "40780/40780 [==============================] - 3s 63us/step - loss: 0.3709 - acc: 0.8301 - val_loss: 0.5640 - val_acc: 0.6873\n",
      "Epoch 3/20\n",
      "40780/40780 [==============================] - 3s 64us/step - loss: 0.3677 - acc: 0.8298 - val_loss: 0.5433 - val_acc: 0.6871\n",
      "Epoch 4/20\n",
      "40780/40780 [==============================] - 3s 63us/step - loss: 0.3649 - acc: 0.8312 - val_loss: 0.5402 - val_acc: 0.6891\n",
      "Epoch 5/20\n",
      "40780/40780 [==============================] - 3s 63us/step - loss: 0.3591 - acc: 0.8329 - val_loss: 0.5447 - val_acc: 0.6838\n",
      "Epoch 6/20\n",
      "40780/40780 [==============================] - 3s 65us/step - loss: 0.3582 - acc: 0.8330 - val_loss: 0.5385 - val_acc: 0.6836\n",
      "Epoch 7/20\n",
      "40780/40780 [==============================] - 3s 65us/step - loss: 0.3595 - acc: 0.8327 - val_loss: 0.5301 - val_acc: 0.6835\n",
      "Epoch 8/20\n",
      "40780/40780 [==============================] - 3s 63us/step - loss: 0.3559 - acc: 0.8339 - val_loss: 0.5362 - val_acc: 0.6902\n",
      "Epoch 9/20\n",
      "40780/40780 [==============================] - 3s 64us/step - loss: 0.3529 - acc: 0.8356 - val_loss: 0.5396 - val_acc: 0.6832\n",
      "Epoch 10/20\n",
      "40780/40780 [==============================] - 3s 64us/step - loss: 0.3516 - acc: 0.8361 - val_loss: 0.5463 - val_acc: 0.6813\n",
      "Epoch 11/20\n",
      "40780/40780 [==============================] - 3s 64us/step - loss: 0.3515 - acc: 0.8360 - val_loss: 0.5392 - val_acc: 0.6815\n",
      "Epoch 12/20\n",
      "40780/40780 [==============================] - 3s 65us/step - loss: 0.3511 - acc: 0.8358 - val_loss: 0.5391 - val_acc: 0.6912\n",
      "Epoch 13/20\n",
      "40780/40780 [==============================] - 3s 66us/step - loss: 0.3517 - acc: 0.8356 - val_loss: 0.5829 - val_acc: 0.6832\n",
      "Epoch 14/20\n",
      "40780/40780 [==============================] - 3s 64us/step - loss: 0.3501 - acc: 0.8370 - val_loss: 0.6775 - val_acc: 0.6817\n",
      "Epoch 15/20\n",
      "40780/40780 [==============================] - 3s 64us/step - loss: 0.3502 - acc: 0.8359 - val_loss: 0.5747 - val_acc: 0.6840\n",
      "Epoch 16/20\n",
      "40780/40780 [==============================] - 3s 63us/step - loss: 0.3488 - acc: 0.8364 - val_loss: 0.5660 - val_acc: 0.6818\n",
      "Epoch 17/20\n",
      "40780/40780 [==============================] - 3s 64us/step - loss: 0.3470 - acc: 0.8366 - val_loss: 0.5584 - val_acc: 0.6865\n",
      "Epoch 18/20\n",
      "40780/40780 [==============================] - 3s 65us/step - loss: 0.3487 - acc: 0.8370 - val_loss: 0.7218 - val_acc: 0.6824\n",
      "Epoch 19/20\n",
      "40780/40780 [==============================] - 3s 66us/step - loss: 0.3496 - acc: 0.8371 - val_loss: 0.5492 - val_acc: 0.6806\n",
      "Epoch 20/20\n",
      "40780/40780 [==============================] - 3s 63us/step - loss: 0.3481 - acc: 0.8363 - val_loss: 0.6484 - val_acc: 0.6828\n",
      "Test loss: 0.6483596493609756\n",
      "Test accuracy: 0.6827916411123353\n"
     ]
    }
   ],
   "source": [
    "#Save Model=ON\n",
    "history = model.fit(X_train, preprocess.y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, preprocess.y_test),shuffle=True,callbacks=callbacks)\n",
    "\n",
    "score = model.evaluate(X_test, preprocess.y_test, verbose=0)\n",
    "\n",
    "#print loss and accuracy\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11317939 0.8868206 ]\n",
      " [0.11317939 0.8868206 ]\n",
      " [0.11317939 0.8868206 ]\n",
      " ...\n",
      " [0.9967469  0.00325306]\n",
      " [0.97680295 0.02319701]\n",
      " [0.97680295 0.02319701]]\n",
      "[1 1 1 ... 0 0 0]\n",
      "[1 1 1 ... 0 0 0]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     normal     0.6137    0.0915    0.1593     13921\n",
      "    anomaly     0.6863    0.9718    0.8045     28477\n",
      "\n",
      "avg / total     0.6625    0.6828    0.5927     42398\n",
      "\n",
      "[[ 1274 12647]\n",
      " [  802 27675]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(y_pred)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(X_test)\n",
    "\n",
    "target_names = ['normal', 'anomaly']\n",
    "print(classification_report(np.argmax(preprocess.y_test, axis=1), y_pred, target_names=target_names, digits=4))\n",
    "print(confusion_matrix(np.argmax(preprocess.y_test, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda]",
   "language": "python",
   "name": "conda-env-Anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
